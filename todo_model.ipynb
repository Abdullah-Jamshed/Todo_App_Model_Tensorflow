{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "1.17.2\n",
      "0.25.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# print(keras.__version__)\n",
    "# print(np.__version__)\n",
    "# print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>concat(d,m,y)</th>\n",
       "      <th>bread</th>\n",
       "      <th>egg</th>\n",
       "      <th>waffles</th>\n",
       "      <th>butter</th>\n",
       "      <th>milk</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>...</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>peach</th>\n",
       "      <th>coriander</th>\n",
       "      <th>mint</th>\n",
       "      <th>tomato</th>\n",
       "      <th>onion</th>\n",
       "      <th>potatoes</th>\n",
       "      <th>garlic</th>\n",
       "      <th>ginger</th>\n",
       "      <th>pepper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day  month  year  concat(d,m,y)  bread  egg  waffles  butter  \\\n",
       "Date                                                                       \n",
       "2018-01-01    1      1    18           1118      1    1        1       1   \n",
       "2018-01-02    2      1    18           2118      1    0        0       0   \n",
       "2018-01-03    3      1    18           3118      0    0        0       0   \n",
       "2018-01-04    4      1    18           4118      1    1        0       0   \n",
       "2018-01-05    5      1    18           5118      1    1        0       0   \n",
       "\n",
       "            milk  yogurt  ...  strawberry  peach  coriander  mint  tomato  \\\n",
       "Date                      ...                                               \n",
       "2018-01-01     1       1  ...           0      1          1     0       1   \n",
       "2018-01-02     1       1  ...           0      0          1     0       0   \n",
       "2018-01-03     1       1  ...           0      0          0     0       1   \n",
       "2018-01-04     1       0  ...           0      0          1     1       1   \n",
       "2018-01-05     1       1  ...           1      1          1     0       1   \n",
       "\n",
       "            onion  potatoes  garlic  ginger  pepper  \n",
       "Date                                                 \n",
       "2018-01-01      1         1       1       1       0  \n",
       "2018-01-02      0         0       0       0       0  \n",
       "2018-01-03      0         0       0       0       0  \n",
       "2018-01-04      0         0       0       0       0  \n",
       "2018-01-05      0         0       1       1       1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('todoData.xlsx', date_parser=True)\n",
    "data = data.set_index('Date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>concat(d,m,y)</th>\n",
       "      <th>bread</th>\n",
       "      <th>egg</th>\n",
       "      <th>waffles</th>\n",
       "      <th>butter</th>\n",
       "      <th>milk</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>...</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>peach</th>\n",
       "      <th>coriander</th>\n",
       "      <th>mint</th>\n",
       "      <th>tomato</th>\n",
       "      <th>onion</th>\n",
       "      <th>potatoes</th>\n",
       "      <th>garlic</th>\n",
       "      <th>ginger</th>\n",
       "      <th>pepper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>15.720548</td>\n",
       "      <td>6.526027</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>52317.678082</td>\n",
       "      <td>0.617808</td>\n",
       "      <td>0.516438</td>\n",
       "      <td>0.108219</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>0.867123</td>\n",
       "      <td>0.735616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.398630</td>\n",
       "      <td>0.667123</td>\n",
       "      <td>0.249315</td>\n",
       "      <td>0.832877</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.080822</td>\n",
       "      <td>0.250685</td>\n",
       "      <td>0.250685</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.802278</td>\n",
       "      <td>3.450215</td>\n",
       "      <td>0.500343</td>\n",
       "      <td>76892.181651</td>\n",
       "      <td>0.486256</td>\n",
       "      <td>0.500072</td>\n",
       "      <td>0.310870</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.441307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400274</td>\n",
       "      <td>0.489952</td>\n",
       "      <td>0.471566</td>\n",
       "      <td>0.432913</td>\n",
       "      <td>0.373342</td>\n",
       "      <td>0.400274</td>\n",
       "      <td>0.272748</td>\n",
       "      <td>0.433705</td>\n",
       "      <td>0.433705</td>\n",
       "      <td>0.400274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11118.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20918.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>30918.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>311219.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day       month        year  concat(d,m,y)       bread  \\\n",
       "count  730.000000  730.000000  730.000000     730.000000  730.000000   \n",
       "mean    15.720548    6.526027   18.500000   52317.678082    0.617808   \n",
       "std      8.802278    3.450215    0.500343   76892.181651    0.486256   \n",
       "min      1.000000    1.000000   18.000000    1118.000000    0.000000   \n",
       "25%      8.000000    4.000000   18.000000   11118.000000    0.000000   \n",
       "50%     16.000000    7.000000   18.500000   20918.500000    1.000000   \n",
       "75%     23.000000   10.000000   19.000000   30918.750000    1.000000   \n",
       "max     31.000000   12.000000   19.000000  311219.000000    1.000000   \n",
       "\n",
       "              egg     waffles      butter        milk      yogurt  ...  \\\n",
       "count  730.000000  730.000000  730.000000  730.000000  730.000000  ...   \n",
       "mean     0.516438    0.108219    0.321918    0.867123    0.735616  ...   \n",
       "std      0.500072    0.310870    0.467532    0.339674    0.441307  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    1.000000    0.000000  ...   \n",
       "50%      1.000000    0.000000    0.000000    1.000000    1.000000  ...   \n",
       "75%      1.000000    0.000000    1.000000    1.000000    1.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "       strawberry       peach   coriander        mint      tomato       onion  \\\n",
       "count  730.000000  730.000000  730.000000  730.000000  730.000000  730.000000   \n",
       "mean     0.200000    0.398630    0.667123    0.249315    0.832877    0.200000   \n",
       "std      0.400274    0.489952    0.471566    0.432913    0.373342    0.400274   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000    0.000000    1.000000    0.000000   \n",
       "75%      0.000000    1.000000    1.000000    0.000000    1.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         potatoes      garlic      ginger      pepper  \n",
       "count  730.000000  730.000000  730.000000  730.000000  \n",
       "mean     0.080822    0.250685    0.250685    0.200000  \n",
       "std      0.272748    0.433705    0.433705    0.400274  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.750000    0.750000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Training, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train ,test= data.iloc[:-100,3:] , data.iloc[-100:,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on 3 days then predciting 4th value\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range (3, train.shape[0]):\n",
    "    x_train.append(train[i-3:i])\n",
    "    y_train.append(train[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling traing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 3, 30)\n",
      "(627, 29)\n"
     ]
    }
   ],
   "source": [
    "#converting traning data into munpy array\n",
    "\n",
    "x_train , y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "y_train = y_train[:,1:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building LSTM network\n",
    "\n",
    "numbers_of_features = 30\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 140, activation = \"relu\", return_sequences = True, input_shape= (x_train.shape[1],30)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 120, activation = \"relu\", return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 100, activation = \"relu\", return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 80, activation = \"relu\"))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(29, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 3, 140)            95760     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 140)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3, 120)            125280    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 120)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 3, 100)            88400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 80)                57920     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                2349      \n",
      "=================================================================\n",
      "Total params: 369,709\n",
      "Trainable params: 369,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "627/627 [==============================] - 3s 4ms/step - loss: 0.5974 - acc: 0.7594\n",
      "Epoch 2/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.5028 - acc: 0.7720\n",
      "Epoch 3/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4987 - acc: 0.7717\n",
      "Epoch 4/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4873 - acc: 0.7740\n",
      "Epoch 5/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4850 - acc: 0.7763\n",
      "Epoch 6/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4776 - acc: 0.7807\n",
      "Epoch 7/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4580 - acc: 0.7924\n",
      "Epoch 8/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4335 - acc: 0.8052\n",
      "Epoch 9/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.4167 - acc: 0.8114\n",
      "Epoch 10/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.3966 - acc: 0.8174\n",
      "Epoch 11/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.3759 - acc: 0.8335\n",
      "Epoch 12/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.3584 - acc: 0.8464\n",
      "Epoch 13/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.3408 - acc: 0.8560\n",
      "Epoch 14/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.3255 - acc: 0.8658\n",
      "Epoch 15/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.3096 - acc: 0.8722\n",
      "Epoch 16/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2950 - acc: 0.8788\n",
      "Epoch 17/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2847 - acc: 0.8810\n",
      "Epoch 18/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2740 - acc: 0.8852\n",
      "Epoch 19/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2720 - acc: 0.8877\n",
      "Epoch 20/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2671 - acc: 0.8887\n",
      "Epoch 21/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2633 - acc: 0.8917\n",
      "Epoch 22/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2591 - acc: 0.8945\n",
      "Epoch 23/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2550 - acc: 0.8969\n",
      "Epoch 24/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.2513 - acc: 0.8967\n",
      "Epoch 25/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2433 - acc: 0.9008\n",
      "Epoch 26/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2429 - acc: 0.9010\n",
      "Epoch 27/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2385 - acc: 0.9045\n",
      "Epoch 28/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.2399 - acc: 0.9029\n",
      "Epoch 29/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2353 - acc: 0.9052\n",
      "Epoch 30/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2328 - acc: 0.9051\n",
      "Epoch 31/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2281 - acc: 0.9078\n",
      "Epoch 32/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2255 - acc: 0.9084\n",
      "Epoch 33/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2168 - acc: 0.9105\n",
      "Epoch 34/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2202 - acc: 0.9109\n",
      "Epoch 35/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2195 - acc: 0.9101\n",
      "Epoch 36/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2152 - acc: 0.9126\n",
      "Epoch 37/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2112 - acc: 0.9143\n",
      "Epoch 38/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2098 - acc: 0.9132\n",
      "Epoch 39/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2091 - acc: 0.9138\n",
      "Epoch 40/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.2069 - acc: 0.9134\n",
      "Epoch 41/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2090 - acc: 0.9128\n",
      "Epoch 42/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2058 - acc: 0.9153\n",
      "Epoch 43/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2105 - acc: 0.9134\n",
      "Epoch 44/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2112 - acc: 0.9135\n",
      "Epoch 45/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.2039 - acc: 0.9164\n",
      "Epoch 46/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1990 - acc: 0.9169\n",
      "Epoch 47/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.2035 - acc: 0.9171\n",
      "Epoch 48/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1991 - acc: 0.9185\n",
      "Epoch 49/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1972 - acc: 0.9186\n",
      "Epoch 50/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1915 - acc: 0.9207\n",
      "Epoch 51/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1927 - acc: 0.9202\n",
      "Epoch 52/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1944 - acc: 0.9191\n",
      "Epoch 53/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1879 - acc: 0.9217\n",
      "Epoch 54/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1882 - acc: 0.9220\n",
      "Epoch 55/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1865 - acc: 0.9232\n",
      "Epoch 56/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1880 - acc: 0.9219\n",
      "Epoch 57/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1878 - acc: 0.9228\n",
      "Epoch 58/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1821 - acc: 0.9240\n",
      "Epoch 59/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1876 - acc: 0.9213\n",
      "Epoch 60/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1792 - acc: 0.9254\n",
      "Epoch 61/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1844 - acc: 0.9244\n",
      "Epoch 62/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1804 - acc: 0.9260\n",
      "Epoch 63/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1743 - acc: 0.9271\n",
      "Epoch 64/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1771 - acc: 0.9243\n",
      "Epoch 65/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1760 - acc: 0.9262\n",
      "Epoch 66/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1741 - acc: 0.9269\n",
      "Epoch 67/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1867 - acc: 0.9237\n",
      "Epoch 68/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1763 - acc: 0.9260\n",
      "Epoch 69/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1728 - acc: 0.9280\n",
      "Epoch 70/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1720 - acc: 0.9286\n",
      "Epoch 71/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1722 - acc: 0.9275\n",
      "Epoch 72/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1655 - acc: 0.9292\n",
      "Epoch 73/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1757 - acc: 0.9259\n",
      "Epoch 74/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1713 - acc: 0.9277\n",
      "Epoch 75/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1692 - acc: 0.9291\n",
      "Epoch 76/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1641 - acc: 0.9300\n",
      "Epoch 77/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1610 - acc: 0.9303\n",
      "Epoch 78/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1616 - acc: 0.9297\n",
      "Epoch 79/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1636 - acc: 0.9305\n",
      "Epoch 80/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1579 - acc: 0.9324\n",
      "Epoch 81/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1591 - acc: 0.9319\n",
      "Epoch 82/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1600 - acc: 0.9311\n",
      "Epoch 83/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1559 - acc: 0.9329\n",
      "Epoch 84/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1622 - acc: 0.9319\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1591 - acc: 0.9310\n",
      "Epoch 86/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1554 - acc: 0.9331\n",
      "Epoch 87/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1571 - acc: 0.9311\n",
      "Epoch 88/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1552 - acc: 0.9322\n",
      "Epoch 89/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1559 - acc: 0.9314\n",
      "Epoch 90/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1532 - acc: 0.9325\n",
      "Epoch 91/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1532 - acc: 0.9337\n",
      "Epoch 92/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1510 - acc: 0.9341\n",
      "Epoch 93/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1516 - acc: 0.9342\n",
      "Epoch 94/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1497 - acc: 0.9337\n",
      "Epoch 95/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1486 - acc: 0.9355\n",
      "Epoch 96/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1475 - acc: 0.9374\n",
      "Epoch 97/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1490 - acc: 0.9348\n",
      "Epoch 98/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1514 - acc: 0.9331\n",
      "Epoch 99/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1477 - acc: 0.9365\n",
      "Epoch 100/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1490 - acc: 0.9358\n",
      "Epoch 101/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1477 - acc: 0.9368\n",
      "Epoch 102/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1473 - acc: 0.9350\n",
      "Epoch 103/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1426 - acc: 0.9376\n",
      "Epoch 104/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1448 - acc: 0.9372\n",
      "Epoch 105/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1450 - acc: 0.9368\n",
      "Epoch 106/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1496 - acc: 0.9370\n",
      "Epoch 107/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1389 - acc: 0.9391\n",
      "Epoch 108/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1385 - acc: 0.9418\n",
      "Epoch 109/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1382 - acc: 0.9388\n",
      "Epoch 110/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1394 - acc: 0.9379\n",
      "Epoch 111/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1371 - acc: 0.9388\n",
      "Epoch 112/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1358 - acc: 0.9407\n",
      "Epoch 113/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1414 - acc: 0.9368\n",
      "Epoch 114/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1358 - acc: 0.9399\n",
      "Epoch 115/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1317 - acc: 0.9428\n",
      "Epoch 116/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1320 - acc: 0.9410\n",
      "Epoch 117/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1291 - acc: 0.9413\n",
      "Epoch 118/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1371 - acc: 0.9387\n",
      "Epoch 119/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1313 - acc: 0.9418\n",
      "Epoch 120/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1297 - acc: 0.9424\n",
      "Epoch 121/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1261 - acc: 0.9435\n",
      "Epoch 122/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1265 - acc: 0.9442\n",
      "Epoch 123/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1336 - acc: 0.9420\n",
      "Epoch 124/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1275 - acc: 0.9432\n",
      "Epoch 125/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1318 - acc: 0.9396\n",
      "Epoch 126/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1289 - acc: 0.9432\n",
      "Epoch 127/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1279 - acc: 0.9419\n",
      "Epoch 128/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1227 - acc: 0.9452\n",
      "Epoch 129/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1241 - acc: 0.9465\n",
      "Epoch 130/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1243 - acc: 0.9460\n",
      "Epoch 131/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1215 - acc: 0.9471\n",
      "Epoch 132/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1172 - acc: 0.9473\n",
      "Epoch 133/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1208 - acc: 0.9460\n",
      "Epoch 134/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1207 - acc: 0.9457\n",
      "Epoch 135/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1233 - acc: 0.9456\n",
      "Epoch 136/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1221 - acc: 0.9452\n",
      "Epoch 137/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1230 - acc: 0.9465\n",
      "Epoch 138/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1165 - acc: 0.9458\n",
      "Epoch 139/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1250 - acc: 0.9442\n",
      "Epoch 140/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1232 - acc: 0.9447\n",
      "Epoch 141/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1208 - acc: 0.9464\n",
      "Epoch 142/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1153 - acc: 0.9493\n",
      "Epoch 143/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1274 - acc: 0.9447\n",
      "Epoch 144/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1242 - acc: 0.9464\n",
      "Epoch 145/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1189 - acc: 0.9473\n",
      "Epoch 146/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1143 - acc: 0.9493\n",
      "Epoch 147/150\n",
      "627/627 [==============================] - 1s 1ms/step - loss: 0.1162 - acc: 0.9484\n",
      "Epoch 148/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1096 - acc: 0.9495\n",
      "Epoch 149/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1155 - acc: 0.9474\n",
      "Epoch 150/150\n",
      "627/627 [==============================] - 1s 2ms/step - loss: 0.1132 - acc: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f89e09696d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compiling the regressor model\n",
    "\n",
    "regressor.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "#training the the model\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs=150, batch_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 3, 30)\n",
      "(97, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(test)\n",
    "test = scaler.fit_transform(test)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(3, test.shape[0]):\n",
    "    x_test.append(test[i-3:i])\n",
    "    y_test.append(test[i])\n",
    "    \n",
    "# converting traning data into munpy array\n",
    "\n",
    "x_test , y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "y_test = y_test[:,1:]\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# predicting item\n",
    "result = regressor.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor.save('todomodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
